{\rtf1\ansi\ansicpg1252\cocoartf1347\cocoasubrtf570
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red170\green13\blue145;\red92\green38\blue153;\red28\green0\blue207;
\red46\green13\blue110;\red196\green26\blue22;\red100\green56\blue32;\red0\green116\blue0;\red14\green14\blue255;
}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab529
\pard\tx529\pardeftab529\pardirnatural

\f0\fs22 \cf2 \CocoaLigature0 void\cf0  MLP_Opencv(\cf3 Mat\cf0  &predict_teste,\cf3 Mat\cf0  &normalizado,\cf3 Mat\cf0  &lable,\cf3 Mat\cf0  &teste,\cf3 Mat\cf0  &teste_lable,\cf3 Mat\cf0  &treino,\cf3 Mat\cf0  &treino_lable,\cf3 Mat\cf0  &organizada,\cf3 Mat\cf0  &organizada_lable,\cf2 int\cf0  config,\cf2 int\cf0  atributos,\cf2 int\cf0  tamanho_teste,\cf2 int\cf0  tamanho_treino,\cf2 int\cf0  classes,\cf2 int\cf0  num_linhas,\cf2 int\cf0  opcao,\cf2 int\cf0  *&vet_classe,\cf2 int\cf0  *&vet_classe_treino)\{\
    \
    \cf2 if\cf0 (opcao==\cf4 0\cf0 )\
    \{\
        hold_out(treino,treino_lable,teste,teste_lable,organizada,organizada_lable,classes,num_linhas,atributos,tamanho_teste,vet_classe,vet_classe_treino);\
	\}\
	\cf2 else\cf0  \cf2 if\cf0 (opcao==\cf4 1\cf0 )\
	\{\
        leave_one_out(normalizado,lable,teste,teste_lable,treino,treino_lable,vet_classe_treino,classes,num_linhas,atributos);\
	\}\
 \
	\cf5 printf\cf0 (\cf6 "\\n\\tSTART MLP\\n\\n"\cf0 );\
 \
	\cf3 Mat\cf0  teste_lable_MLP(tamanho_teste,classes,\cf7 CV_32F\cf0 );\
	\cf3 Mat\cf0  treino_lable_MLP(tamanho_treino,classes,\cf7 CV_32F\cf0 );\
	\cf3 Mat\cf0  classificationResult(\cf4 1\cf0 , classes, \cf7 CV_32FC1\cf0 );\
	\cf3 Mat\cf0  layers(\cf4 3\cf0 ,\cf4 1\cf0 ,\cf7 CV_32S\cf0 );\
	\
	\cf2 int\cf0  x,y;\
	\cf2 int\cf0  val;\
 \
	\cf2 for\cf0 (y=\cf4 0\cf0 ;y<tamanho_teste;y++)\
	\{\
        val = (\cf2 int\cf0 )teste_lable.at<\cf2 float\cf0 >(y,\cf4 0\cf0 );\
        \cf2 for\cf0 (x=\cf4 0\cf0 ;x<classes;x++)\
        \{\
            \cf2 if\cf0 (val==x)\
            \{\
                teste_lable_MLP.at<\cf2 float\cf0 >(y,x) = \cf4 1\cf0 ;\
            \}\
            \cf2 else\cf0 \
            \{\
                teste_lable_MLP.at<\cf2 float\cf0 >(y,x) = \cf4 0\cf0 ;\
            \}\
        \}\
	\}\
        \cf2 for\cf0 (y=\cf4 0\cf0 ;y<tamanho_treino;y++)\
        \{\
            val = (\cf2 int\cf0 )treino_lable.at<\cf2 float\cf0 >(y,\cf4 0\cf0 );\
            \cf2 for\cf0 (x=\cf4 0\cf0 ;x<classes;x++)\
            \{\
                \cf2 if\cf0 (val==x)\
                \{\
                    treino_lable_MLP.at<\cf2 float\cf0 >(y,x) = \cf4 1\cf0 ;\
                \}\
                \cf2 else\cf0 \
                \{\
                    treino_lable_MLP.at<\cf2 float\cf0 >(y,x) = \cf4 0\cf0 ;\
                \}\
            \}\
        \}\
 \
    \cf2 int\cf0  numHiddenLayer;\
	\cf2 switch\cf0  (config)\{\
        \cf2 case\cf0  \cf4 1\cf0 :\
            numHiddenLayer = (classes+atributos)/\cf4 2\cf0 ;\
            layers.at<\cf2 int\cf0 >(\cf4 0\cf0 ,\cf4 0\cf0 ) =atributos;\cf8 //input layer\cf0 \
            layers.at<\cf2 int\cf0 >(\cf4 1\cf0 ,\cf4 0\cf0 )=numHiddenLayer;\cf8 //hidden layer\cf0 \
            layers.at<\cf2 int\cf0 >(\cf4 2\cf0 ,\cf4 0\cf0 ) =classes;\cf8 //output layer\cf0 \
            \cf2 break\cf0 ;\
        \cf2 case\cf0  \cf4 2\cf0 :\
            numHiddenLayer = (classes+atributos)*\cf4 2\cf0 /\cf4 3\cf0 ;\
            layers.at<\cf2 int\cf0 >(\cf4 0\cf0 ,\cf4 0\cf0 ) = atributos;\cf8 //input layer\cf0 \
            layers.at<\cf2 int\cf0 >(\cf4 1\cf0 ,\cf4 0\cf0 )=numHiddenLayer;\cf8 //hidden layer\cf0 \
            layers.at<\cf2 int\cf0 >(\cf4 2\cf0 ,\cf4 0\cf0 ) =classes;\cf8 //output layer\cf0 \
            \cf2 break\cf0 ;\
        \cf2 default\cf0 :\
            numHiddenLayer = (classes+atributos)/\cf4 2\cf0 ;\
            layers.at<\cf2 int\cf0 >(\cf4 0\cf0 ,\cf4 0\cf0 ) = atributos;\cf8 //input layer\cf0 \
            layers.at<\cf2 int\cf0 >(\cf4 1\cf0 ,\cf4 0\cf0 )=numHiddenLayer;\cf8 //hidden layer\cf0 \
            layers.at<\cf2 int\cf0 >(\cf4 2\cf0 ,\cf4 0\cf0 ) =classes;\cf8 //output layer\cf0 \
            \cf2 break\cf0 ;\
    \}\
	CvANN_MLP nnetwork(layers, CvANN_MLP::SIGMOID_SYM,\cf4 0.6\cf0 ,\cf4 1\cf0 );\
	CvANN_MLP_TrainParams params(\
 \cf8 // terminate the training after either 1000\cf0 \
 \cf8 // iterations or a very small change in the\cf0 \
 \cf8 // network wieghts below the specified value\cf0 \
 cvTermCriteria(CV_TERMCRIT_ITER+CV_TERMCRIT_EPS, \cf4 1000\cf0 , \cf4 0.000001\cf0 ),\
 \cf8 // use backpropogation for training\cf0 \
 CvANN_MLP_TrainParams::BACKPROP,\
 \cf8 // co-efficents for backpropogation training\cf0 \
 \cf8 // recommended values taken from {\field{\*\fldinst{HYPERLINK "http://docs.opencv.org/modules/ml/doc/neural_networks.html#cvann-mlp-trainparams"}}{\fldrslt \cf9 http://docs.opencv.org/modules/ml/doc/neural_networks.html#cvann-mlp-trainparams}}\cf0 \
 \cf4 0.1\cf0 ,\
 \cf4 0.1\cf0 );\
	\cf8 // train the neural network (using training data)\cf0 \
 \
 \cf2 int\cf0  iterations = nnetwork.train(treino, treino_lable_MLP,cv::Mat(),cv::Mat(),params);\
 \
 Mat linha_teste;\
 \
	\cf2 float\cf0  cont_acerto = \cf4 0\cf0 ;\
	\cf2 int\cf0  cont_erro = \cf4 0\cf0 ;\
	\cf2 int\cf0  numClassses = classes;\
	\
	\cf2 for\cf0  (\cf2 int\cf0  tsample = \cf4 0\cf0 ; tsample < tamanho_teste; tsample++)\
	\{\
        \cf8 // extract the sample\cf0 \
        linha_teste = teste.row(tsample);\
        \cf8 //try to predict its class\cf0 \
        nnetwork.predict(linha_teste, classificationResult);\
        \cf8 /*The classification result matrix holds weightage  of each class.\
         we take the class with the highest weightage as the resultant class */\cf0 \
\
        \cf8 // find the class with maximum weightage.\cf0 \
        \cf2 int\cf0  maxIndex = \cf4 0\cf0 ;\
        \cf2 float\cf0  value=\cf4 0.0f\cf0 ;\
        \cf2 float\cf0  maxValue=classificationResult.at<\cf2 float\cf0 >(\cf4 0\cf0 ,\cf4 0\cf0 );\
        \cf2 for\cf0 (\cf2 int\cf0  index=\cf4 1\cf0 ;index<classes;index++)\
        \{\
            value = classificationResult.at<\cf2 float\cf0 >(\cf4 0\cf0 ,index);\
                \cf2 if\cf0 (value>maxValue)\
                \{\
                    maxValue = value;\
                    maxIndex=index;\
                \}\
        \}\
\
        \cf2 if\cf0  (teste_lable_MLP.at<\cf2 float\cf0 >(tsample, maxIndex)!=\cf4 1.0f\cf0 )\
        \{\
            \cf8 // if they differ more than floating point error => wrong class\cf0 \
            cont_erro++;\
    \
            \cf8 //find the actual label 'class_index'\cf0 \
            \cf2 for\cf0 (\cf2 int\cf0  class_index=\cf4 0\cf0 ;class_index<classes;class_index++)\
            \{\
                \cf2 if\cf0 (teste_lable_MLP.at<\cf2 float\cf0 >(tsample, class_index)==\cf4 1.0f\cf0 )\
                \{\
                    predict_teste.at<\cf2 float\cf0 >(maxIndex,class_index)++;\cf8 //matriz para fazer matriz confusao\cf0 \
                    \cf2 break\cf0 ;\
                \}\
            \}\
        \}\
        \cf2 else\cf0 \
        \{\
            cont_acerto++;\
            predict_teste.at<\cf2 float\cf0 >(maxIndex,maxIndex)++;\cf8 //matriz para fazer matriz confusao\cf0 \
        \}\
    \}\
    \cf2 float\cf0  percent_acerto=(cont_acerto/tamanho_teste);\
    printf(\cf6 "A taxa de acerto foi de : %f\\n"\cf0 ,percent_acerto);\
    printf(\cf6 "O percentual de acerto foi de : %f %\\n"\cf0 ,percent_acerto*\cf4 100.0\cf0 );\
    printf(\cf6 "\\t END MLP\\n\\n"\cf0 );\
\
    linha_teste.release();\
    teste_lable_MLP.release();\
    treino_lable_MLP.release();\
    classificationResult.release();\
    layers.release();\
\}}